{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDMWt0QJO13P"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "POcckcBeO13Q"
      },
      "outputs": [],
      "source": [
        "from os import path\n",
        "import pandas as pd\n",
        "from pprint import PrettyPrinter, pprint\n",
        "from typing import Optional\n",
        "\n",
        "__DIR__ = globals()['_dh'][0]\n",
        "data_dir = path.relpath(path.join(__DIR__, \"..\", \"_data\"))\n",
        "\n",
        "pp = PrettyPrinter(indent=2, width=120)\n",
        "\n",
        "pd.set_option('display.width', 120)\n",
        "pd.set_option('display.max_colwidth', 90)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GuSBBGmKO13R"
      },
      "outputs": [],
      "source": [
        "# Settings\n",
        "_testing = False\n",
        "_colab_install = True\n",
        "_pm_log_sections = False\n",
        "\n",
        "# Parameters\n",
        "dataset_dir = path.join(data_dir, \"wiki\", \"20220301.en.1gb\")\n",
        "apply_pii_remediation = True\n",
        "\n",
        "base_model = \"bert-base-cased\"\n",
        "max_length = 128\n",
        "vocab_size = 20_000\n",
        "\n",
        "tokenizer_dir = path.join(data_dir, \"pretrain\", \"tokenizer\")\n",
        "tokenize_params = dict(batched=True, num_proc=4)\n",
        "\n",
        "mlm_probability = 0.15\n",
        "bert_config = dict()\n",
        "training_args = dict(\n",
        "    optim = \"adamw_torch\",\n",
        "    num_train_epochs = 1,\n",
        "    per_device_train_batch_size = 64,\n",
        "    eval_accumulation_steps = 10,\n",
        "    evaluation_strategy = \"steps\",\n",
        "    logging_steps = 10000,\n",
        "    save_steps = 10000,\n",
        "    save_total_limit = 3,\n",
        ")\n",
        "max_eval_samples: Optional[int] = 5000\n",
        "model_dir = path.join(data_dir, \"pretrain\", \"model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_dlx8mrVlZeO"
      },
      "outputs": [],
      "source": [
        "if _testing:\n",
        "    dataset = path.join(data_dir, \"wiki\", \"20220301.en.test\")\n",
        "\n",
        "    training_args.update(dict(\n",
        "        max_steps = 3,\n",
        "        logging_steps = 1,\n",
        "    ))\n",
        "\n",
        "    max_eval_samples = 1000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQEU19DRO13R"
      },
      "source": [
        "## Process settings / parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHYTYXePWJQK",
        "outputId": "e3dfc14a-9e7a-428a-c221-bcb507b3c25a"
      },
      "outputs": [],
      "source": [
        "# Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    \n",
        "    # Wrap output text\n",
        "    from IPython.display import HTML, display\n",
        "    \n",
        "    def set_css():\n",
        "        display(HTML('''\n",
        "        <style>\n",
        "            pre {\n",
        "                white-space: pre-wrap;\n",
        "            }\n",
        "        </style>\n",
        "        '''))\n",
        "        get_ipython().events.register('pre_run_cell', set_css)\n",
        "    \n",
        "    if _colab_install:\n",
        "        colab_install_script = path.join(__DIR__, \"..\", \"colab_install.sh\")\n",
        "\n",
        "        if not path.isfile(colab_install_script):\n",
        "            script_url = (\"https://raw.githubusercontent.com/\"\n",
        "                            \"yenson-lau/pii-remediation/main/colab_install.sh\")\n",
        "            !wget $script_url -O $colab_install_script\n",
        "\n",
        "        !bash $colab_install_script\n",
        "\n",
        "        print()\n",
        "\n",
        "except ModuleNotFoundError:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmlWPmfAO13R",
        "outputId": "cc7c1267-dd57-4a06-f1ac-78a017f7444c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameters:\n",
            "OrderedDict([ ('dataset_dir', '../_data/wiki/20220301.en.1gb'),\n",
            "              ('base_model', 'bert-base-cased'),\n",
            "              ('max_length', 128),\n",
            "              ('vocab_size', 20000),\n",
            "              ('tokenizer_dir', '../_data/pretrain/tokenizer'),\n",
            "              ('tokenize_params', {'batched': True, 'num_proc': 4}),\n",
            "              ('mlm_probability', 0.15),\n",
            "              ('bert_config', {}),\n",
            "              ( 'training_args',\n",
            "                { 'eval_accumulation_steps': 10,\n",
            "                  'evaluation_strategy': 'steps',\n",
            "                  'logging_steps': 10000,\n",
            "                  'num_train_epochs': 1,\n",
            "                  'optim': 'adamw_torch',\n",
            "                  'per_device_train_batch_size': 64,\n",
            "                  'save_steps': 10000,\n",
            "                  'save_total_limit': 3}),\n",
            "              ('max_eval_samples', 5000),\n",
            "              ('model_dir', '../_data/pretrain/model')])\n"
          ]
        }
      ],
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "if _pm_log_sections:\n",
        "    def pm_log_section(message):\n",
        "        print(f\"\\n[===== {message} =====]\\n\")\n",
        "else:\n",
        "    def pm_log_section(message):\n",
        "        return\n",
        "\n",
        "if _testing:\n",
        "    pm_log_section(\"Running on testing mode\")\n",
        "\n",
        "config = OrderedDict(\n",
        "    dataset_dir = dataset_dir,\n",
        "\n",
        "    base_model = base_model,\n",
        "    max_length = max_length,\n",
        "    vocab_size = vocab_size,\n",
        "\n",
        "    tokenizer_dir = tokenizer_dir,\n",
        "    tokenize_params = tokenize_params,\n",
        "\n",
        "    mlm_probability = mlm_probability,\n",
        "    bert_config = bert_config,\n",
        "    training_args = training_args,\n",
        "    max_eval_samples = max_eval_samples,\n",
        "    model_dir = model_dir,\n",
        ")\n",
        "\n",
        "print(f\"{'TESTING ' if _testing else ''}Parameters:\")\n",
        "pp.pprint(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnoYt-92O13S"
      },
      "source": [
        "# Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499,
          "referenced_widgets": [
            "cf9c1c7d78bf4c35aebe6345fa42247a",
            "c0a41c2c21f545b883d726044efc0e57",
            "c198afd63ae14c92a68b03b8c9938d22",
            "c6f1c2ee06724432bc9762befd3adf2d",
            "d196d72c57cc48659679cf0b596a9013",
            "3c694b6cd16c4a3ba89d852e698743f9",
            "ac0b159991074b0aa67b5c0e1a80d327",
            "af26006679384cf6934af5f35e5e600a",
            "1fa8e54f823b468a9625a7dad673955c",
            "94f985d3ddd346d5af1f30bf323d032c",
            "081bbf8a01104c21bf3aeffcabf5c911",
            "422200b605f74cc984a9978adbf4c22f",
            "96e9641def944faabd4b23fa78a390d2",
            "9e1375057d7e4798bb6f8b4812d264a8",
            "658635f4acfe4d6aa71799c4ed291660",
            "845eba9a96a54285b4fb56e74fb0ed0c",
            "5afcfb79d58a4f5bb5fa841d6342ed8b",
            "1a55c335945642dd91cd971e1ab3882a",
            "781884de5de9499595b98c4aeba39558",
            "e2e28cce613f446f99f1f9ce2a975c72",
            "158ba31be3c2431491108889cb9cdbf6",
            "aafc33167e5d48aa886efcb0c1ae0fe0"
          ]
        },
        "id": "6rw7d1wtO13S",
        "outputId": "29fe3eaa-d653-48ba-baa0-99cdb4b77b32"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-10-25 21:19:52,378 : MainProcess : WARNING : Using custom data configuration default-faec17ab93a39612\n",
            "2022-10-25 21:19:52,380 : MainProcess : WARNING : Reusing dataset json (/Users/yenson/.cache/huggingface/datasets/json/default-faec17ab93a39612/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "47a6804c25874fd5b6aae8e10581f999",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-10-25 21:19:52,631 : MainProcess : WARNING : Using custom data configuration default-b66683a349094466\n",
            "2022-10-25 21:19:52,633 : MainProcess : WARNING : Reusing dataset json (/Users/yenson/.cache/huggingface/datasets/json/default-b66683a349094466/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4be23427ea4d469fa7173c529a3dbb5b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article_id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14877816</td>\n",
              "      <td>Myeloid cell Nuclear Differentiation Antigen is a protein that in humans is encoded as...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14877816</td>\n",
              "      <td>The myeloid cell nuclear differentiation antigen (MNDA) is detected only in nuclei of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>14877816</td>\n",
              "      <td>A 200-amino acid region of human MNDA is strikingly similar to a region in the protein...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14877816</td>\n",
              "      <td>The 1.8-kb MNDA mRNA, which contains an interferon-stimulated response element in the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>14877816</td>\n",
              "      <td>MNDA is located within 2,200 kb of FCER1A, APCS, CRP, and SPTA1.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>14877816</td>\n",
              "      <td>In its pattern of expression and/or regulation, MNDA resembles IFI16, suggesting that ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4845938</td>\n",
              "      <td>\"Boris the Spider\" is a song written by the Who's bass guitarist, John Entwistle.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>4845938</td>\n",
              "      <td>It appears as the second track of their 1966 album A Quick One.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>4845938</td>\n",
              "      <td>This song is claimed to be Entwistle's first composition, and became a staple of live ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>4845938</td>\n",
              "      <td>This song, along with \"My Wife\", \"Heaven and Hell\" and \"The Quiet One\", were Entwistle...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   article_id                                                                                       text\n",
              "0    14877816  Myeloid cell Nuclear Differentiation Antigen is a protein that in humans is encoded as...\n",
              "1    14877816  The myeloid cell nuclear differentiation antigen (MNDA) is detected only in nuclei of ...\n",
              "2    14877816  A 200-amino acid region of human MNDA is strikingly similar to a region in the protein...\n",
              "3    14877816  The 1.8-kb MNDA mRNA, which contains an interferon-stimulated response element in the ...\n",
              "4    14877816                           MNDA is located within 2,200 kb of FCER1A, APCS, CRP, and SPTA1.\n",
              "5    14877816  In its pattern of expression and/or regulation, MNDA resembles IFI16, suggesting that ...\n",
              "6     4845938          \"Boris the Spider\" is a song written by the Who's bass guitarist, John Entwistle.\n",
              "7     4845938                            It appears as the second track of their 1966 album A Quick One.\n",
              "8     4845938  This song is claimed to be Entwistle's first composition, and became a staple of live ...\n",
              "9     4845938  This song, along with \"My Wife\", \"Heaven and Hell\" and \"The Quiet One\", were Entwistle..."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import Dataset, load_dataset\n",
        "\n",
        "pm_log_section(\"Loading dataset\")\n",
        "\n",
        "dataset = dict()\n",
        "for split in [\"train\", \"val\"]:\n",
        "    data_file = path.join(dataset_dir, f\"{split}_data.json\")\n",
        "    if not path.isfile(data_file):  data_file += \".gz\"\n",
        "    dataset[split] = load_dataset(\"json\", data_files=data_file, field=\"data\")[\"train\"]\n",
        "\n",
        "    if ((split != \"train\") \n",
        "        and (max_eval_samples is not None) \n",
        "        and (len(dataset[split]) > max_eval_samples)):\n",
        "        \n",
        "        dataset[split] = dataset[split].select(range(max_eval_samples))\n",
        "\n",
        "display(pd.DataFrame(dataset[\"train\"][:10]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d3fa04bc9b1846b98ec3f15bac639e83",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/9403586 [00:00<?, ?ex/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/Users/yenson/Work/pii-remediation/pii_remediation/pretrain.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yenson/Work/pii-remediation/pii_remediation/pretrain.ipynb#X32sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yenson/Work/pii-remediation/pii_remediation/pretrain.ipynb#X32sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m             \u001b[39mreturn\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m: apply_anonymization(ex[\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m])[\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m]}\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/yenson/Work/pii-remediation/pii_remediation/pretrain.ipynb#X32sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     anon_dataset \u001b[39m=\u001b[39m {\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yenson/Work/pii-remediation/pii_remediation/pretrain.ipynb#X32sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         k: v\u001b[39m.\u001b[39mmap(anon_function, load_from_cache_file\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yenson/Work/pii-remediation/pii_remediation/pretrain.ipynb#X32sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m dataset\u001b[39m.\u001b[39mitems()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yenson/Work/pii-remediation/pii_remediation/pretrain.ipynb#X32sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     }\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yenson/Work/pii-remediation/pii_remediation/pretrain.ipynb#X32sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m display(pd\u001b[39m.\u001b[39mDataFrame(anon_dataset[\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m][:\u001b[39m10\u001b[39m]))\n",
            "\u001b[1;32m/Users/yenson/Work/pii-remediation/pii_remediation/pretrain.ipynb Cell 10\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yenson/Work/pii-remediation/pii_remediation/pretrain.ipynb#X32sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yenson/Work/pii-remediation/pii_remediation/pretrain.ipynb#X32sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m             \u001b[39mreturn\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m: apply_anonymization(ex[\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m])[\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m]}\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yenson/Work/pii-remediation/pii_remediation/pretrain.ipynb#X32sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     anon_dataset \u001b[39m=\u001b[39m {\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/yenson/Work/pii-remediation/pii_remediation/pretrain.ipynb#X32sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         k: v\u001b[39m.\u001b[39;49mmap(anon_function, load_from_cache_file\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yenson/Work/pii-remediation/pii_remediation/pretrain.ipynb#X32sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m dataset\u001b[39m.\u001b[39mitems()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yenson/Work/pii-remediation/pii_remediation/pretrain.ipynb#X32sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     }\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yenson/Work/pii-remediation/pii_remediation/pretrain.ipynb#X32sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m display(pd\u001b[39m.\u001b[39mDataFrame(anon_dataset[\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m][:\u001b[39m10\u001b[39m]))\n",
            "File \u001b[0;32m~/.mambaforge/envs/pii/lib/python3.10/site-packages/datasets/arrow_dataset.py:2387\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   2384\u001b[0m disable_tqdm \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m logging\u001b[39m.\u001b[39mis_progress_bar_enabled()\n\u001b[1;32m   2386\u001b[0m \u001b[39mif\u001b[39;00m num_proc \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m num_proc \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m-> 2387\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_map_single(\n\u001b[1;32m   2388\u001b[0m         function\u001b[39m=\u001b[39;49mfunction,\n\u001b[1;32m   2389\u001b[0m         with_indices\u001b[39m=\u001b[39;49mwith_indices,\n\u001b[1;32m   2390\u001b[0m         with_rank\u001b[39m=\u001b[39;49mwith_rank,\n\u001b[1;32m   2391\u001b[0m         input_columns\u001b[39m=\u001b[39;49minput_columns,\n\u001b[1;32m   2392\u001b[0m         batched\u001b[39m=\u001b[39;49mbatched,\n\u001b[1;32m   2393\u001b[0m         batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m   2394\u001b[0m         drop_last_batch\u001b[39m=\u001b[39;49mdrop_last_batch,\n\u001b[1;32m   2395\u001b[0m         remove_columns\u001b[39m=\u001b[39;49mremove_columns,\n\u001b[1;32m   2396\u001b[0m         keep_in_memory\u001b[39m=\u001b[39;49mkeep_in_memory,\n\u001b[1;32m   2397\u001b[0m         load_from_cache_file\u001b[39m=\u001b[39;49mload_from_cache_file,\n\u001b[1;32m   2398\u001b[0m         cache_file_name\u001b[39m=\u001b[39;49mcache_file_name,\n\u001b[1;32m   2399\u001b[0m         writer_batch_size\u001b[39m=\u001b[39;49mwriter_batch_size,\n\u001b[1;32m   2400\u001b[0m         features\u001b[39m=\u001b[39;49mfeatures,\n\u001b[1;32m   2401\u001b[0m         disable_nullable\u001b[39m=\u001b[39;49mdisable_nullable,\n\u001b[1;32m   2402\u001b[0m         fn_kwargs\u001b[39m=\u001b[39;49mfn_kwargs,\n\u001b[1;32m   2403\u001b[0m         new_fingerprint\u001b[39m=\u001b[39;49mnew_fingerprint,\n\u001b[1;32m   2404\u001b[0m         disable_tqdm\u001b[39m=\u001b[39;49mdisable_tqdm,\n\u001b[1;32m   2405\u001b[0m         desc\u001b[39m=\u001b[39;49mdesc,\n\u001b[1;32m   2406\u001b[0m     )\n\u001b[1;32m   2407\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2409\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mformat_cache_file_name\u001b[39m(cache_file_name, rank):\n",
            "File \u001b[0;32m~/.mambaforge/envs/pii/lib/python3.10/site-packages/datasets/arrow_dataset.py:557\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[39mself\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    556\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 557\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    558\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[1;32m    559\u001b[0m \u001b[39mfor\u001b[39;00m dataset \u001b[39min\u001b[39;00m datasets:\n\u001b[1;32m    560\u001b[0m     \u001b[39m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
            "File \u001b[0;32m~/.mambaforge/envs/pii/lib/python3.10/site-packages/datasets/arrow_dataset.py:524\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    517\u001b[0m self_format \u001b[39m=\u001b[39m {\n\u001b[1;32m    518\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_type,\n\u001b[1;32m    519\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mformat_kwargs\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_kwargs,\n\u001b[1;32m    520\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_columns,\n\u001b[1;32m    521\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39moutput_all_columns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_all_columns,\n\u001b[1;32m    522\u001b[0m }\n\u001b[1;32m    523\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 524\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    525\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[1;32m    526\u001b[0m \u001b[39m# re-apply format to the output\u001b[39;00m\n",
            "File \u001b[0;32m~/.mambaforge/envs/pii/lib/python3.10/site-packages/datasets/fingerprint.py:480\u001b[0m, in \u001b[0;36mfingerprint_transform.<locals>._fingerprint.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m             validate_fingerprint(kwargs[fingerprint_name])\n\u001b[1;32m    478\u001b[0m \u001b[39m# Call actual function\u001b[39;00m\n\u001b[0;32m--> 480\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    482\u001b[0m \u001b[39m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[39mif\u001b[39;00m inplace:  \u001b[39m# update after calling func so that the fingerprint doesn't change if the function fails\u001b[39;00m\n",
            "File \u001b[0;32m~/.mambaforge/envs/pii/lib/python3.10/site-packages/datasets/arrow_dataset.py:2756\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset, disable_tqdm, desc, cache_only)\u001b[0m\n\u001b[1;32m   2754\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m batched:\n\u001b[1;32m   2755\u001b[0m     \u001b[39mfor\u001b[39;00m i, example \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(pbar):\n\u001b[0;32m-> 2756\u001b[0m         example \u001b[39m=\u001b[39m apply_function_on_filtered_inputs(example, i, offset\u001b[39m=\u001b[39;49moffset)\n\u001b[1;32m   2757\u001b[0m         \u001b[39mif\u001b[39;00m update_data:\n\u001b[1;32m   2758\u001b[0m             \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
            "File \u001b[0;32m~/.mambaforge/envs/pii/lib/python3.10/site-packages/datasets/arrow_dataset.py:2655\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[0;34m(inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   2653\u001b[0m \u001b[39mif\u001b[39;00m with_rank:\n\u001b[1;32m   2654\u001b[0m     additional_args \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (rank,)\n\u001b[0;32m-> 2655\u001b[0m processed_inputs \u001b[39m=\u001b[39m function(\u001b[39m*\u001b[39;49mfn_args, \u001b[39m*\u001b[39;49madditional_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfn_kwargs)\n\u001b[1;32m   2656\u001b[0m \u001b[39mif\u001b[39;00m update_data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2657\u001b[0m     \u001b[39m# Check if the function returns updated examples\u001b[39;00m\n\u001b[1;32m   2658\u001b[0m     update_data \u001b[39m=\u001b[39m \u001b[39misinstance\u001b[39m(processed_inputs, (Mapping, pa\u001b[39m.\u001b[39mTable))\n",
            "File \u001b[0;32m~/.mambaforge/envs/pii/lib/python3.10/site-packages/datasets/arrow_dataset.py:2347\u001b[0m, in \u001b[0;36mDataset.map.<locals>.decorate.<locals>.decorated\u001b[0;34m(item, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2343\u001b[0m decorated_item \u001b[39m=\u001b[39m (\n\u001b[1;32m   2344\u001b[0m     Example(item, features\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m batched \u001b[39melse\u001b[39;00m Batch(item, features\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures)\n\u001b[1;32m   2345\u001b[0m )\n\u001b[1;32m   2346\u001b[0m \u001b[39m# Use the LazyDict internally, while mapping the function\u001b[39;00m\n\u001b[0;32m-> 2347\u001b[0m result \u001b[39m=\u001b[39m f(decorated_item, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2348\u001b[0m \u001b[39m# Return a standard dict\u001b[39;00m\n\u001b[1;32m   2349\u001b[0m \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39mdata \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(result, LazyDict) \u001b[39melse\u001b[39;00m result\n",
            "\u001b[1;32m/Users/yenson/Work/pii-remediation/pii_remediation/pretrain.ipynb Cell 10\u001b[0m in \u001b[0;36manon_function\u001b[0;34m(ex)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yenson/Work/pii-remediation/pii_remediation/pretrain.ipynb#X32sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m: apply_anonymization(texts)[\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39msplitlines()}\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yenson/Work/pii-remediation/pii_remediation/pretrain.ipynb#X32sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yenson/Work/pii-remediation/pii_remediation/pretrain.ipynb#X32sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m: apply_anonymization(ex[\u001b[39m\"\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m\"\u001b[39;49m])[\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m]}\n",
            "File \u001b[0;32m~/Work/pii-remediation/pii_remediation/pii.py:57\u001b[0m, in \u001b[0;36mapply_anonymization\u001b[0;34m(sentence, lang_id, context_window, anonymize_condition, tag_type, device)\u001b[0m\n\u001b[1;32m     54\u001b[0m ner\u001b[39m.\u001b[39msort(key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m a: a[\u001b[39m1\u001b[39m])\n\u001b[1;32m     56\u001b[0m \u001b[39mif\u001b[39;00m anonymize_condition:\n\u001b[0;32m---> 57\u001b[0m     new_sentence, new_ner, _ \u001b[39m=\u001b[39m augment_anonymize(sentence, lang_id, ner, )\n\u001b[1;32m     58\u001b[0m     doc \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m: new_sentence, \u001b[39m'\u001b[39m\u001b[39mner\u001b[39m\u001b[39m'\u001b[39m: new_ner, \u001b[39m'\u001b[39m\u001b[39morig_text\u001b[39m\u001b[39m'\u001b[39m: sentence, \u001b[39m'\u001b[39m\u001b[39morig_ner\u001b[39m\u001b[39m'\u001b[39m: ner}\n\u001b[1;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n",
            "File \u001b[0;32m~/Work/pii-remediation/pii_remediation/../muliwai/faker_manager.py:373\u001b[0m, in \u001b[0;36maugment_anonymize\u001b[0;34m(sentence, lang_id, ner, tag_type, faker, context, do_augment)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39maugment_anonymize\u001b[39m(sentence, lang_id, ner, tag_type\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mIP_ADDRESS\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mKEY\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mID\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mPHONE\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mUSER\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mEMAIL\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mLICENSE_PLATE\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mPERSON\u001b[39m\u001b[39m'\u001b[39m}, faker\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, do_augment\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    372\u001b[0m   \u001b[39mif\u001b[39;00m faker \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 373\u001b[0m     faker \u001b[39m=\u001b[39m FakerExtensions(lang_id)\n\u001b[1;32m    374\u001b[0m   \u001b[39mif\u001b[39;00m context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    375\u001b[0m     context \u001b[39m=\u001b[39m {}\n",
            "File \u001b[0;32m~/Work/pii-remediation/pii_remediation/../muliwai/faker_manager.py:106\u001b[0m, in \u001b[0;36mFakerExtensions.__init__\u001b[0;34m(self, lang, trials, faker)\u001b[0m\n\u001b[1;32m    104\u001b[0m   faker \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfaker \u001b[39m=\u001b[39m Faker(\u001b[39m\"\u001b[39m\u001b[39men_GB\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    105\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 106\u001b[0m   faker \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfaker \u001b[39m=\u001b[39m Faker(random\u001b[39m.\u001b[39;49mchoice(faker_map[\u001b[39m\"\u001b[39;49m\u001b[39mes\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39mif\u001b[39;49;00m lang \u001b[39min\u001b[39;49;00m (\u001b[39m\"\u001b[39;49m\u001b[39meu\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mca\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39melse\u001b[39;49;00m \u001b[39m\"\u001b[39;49m\u001b[39mhi\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39mif\u001b[39;49;00m lang \u001b[39min\u001b[39;49;00m (\u001b[39m\"\u001b[39;49m\u001b[39mas\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mgu\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mpa\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mbn\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mur\u001b[39;49m\u001b[39m\"\u001b[39;49m, ) \u001b[39melse\u001b[39;49;00m lang]))\n\u001b[1;32m    107\u001b[0m faker\u001b[39m.\u001b[39madd_provider(person)\n\u001b[1;32m    108\u001b[0m faker\u001b[39m.\u001b[39madd_provider(ssn)\n",
            "File \u001b[0;32m~/.mambaforge/envs/pii/lib/python3.10/site-packages/faker/proxy.py:67\u001b[0m, in \u001b[0;36mFaker.__init__\u001b[0;34m(self, locale, providers, generator, includes, use_weighting, **config)\u001b[0m\n\u001b[1;32m     64\u001b[0m     locales \u001b[39m=\u001b[39m [DEFAULT_LOCALE]\n\u001b[1;32m     66\u001b[0m \u001b[39mfor\u001b[39;00m locale \u001b[39min\u001b[39;00m locales:\n\u001b[0;32m---> 67\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_factory_map[locale] \u001b[39m=\u001b[39m Factory\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m     68\u001b[0m         locale,\n\u001b[1;32m     69\u001b[0m         providers,\n\u001b[1;32m     70\u001b[0m         generator,\n\u001b[1;32m     71\u001b[0m         includes,\n\u001b[1;32m     72\u001b[0m         use_weighting\u001b[39m=\u001b[39;49muse_weighting,\n\u001b[1;32m     73\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mconfig,\n\u001b[1;32m     74\u001b[0m     )\n\u001b[1;32m     76\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_locales \u001b[39m=\u001b[39m locales\n\u001b[1;32m     77\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_factories \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_factory_map\u001b[39m.\u001b[39mvalues())\n",
            "File \u001b[0;32m~/.mambaforge/envs/pii/lib/python3.10/site-packages/faker/factory.py:57\u001b[0m, in \u001b[0;36mFactory.create\u001b[0;34m(cls, locale, providers, generator, includes, use_weighting, **config)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[39mif\u001b[39;00m prov_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfaker.providers\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     55\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m prov_cls, lang_found, _ \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_find_provider_class(prov_name, locale)\n\u001b[1;32m     58\u001b[0m provider \u001b[39m=\u001b[39m prov_cls(faker)\n\u001b[1;32m     59\u001b[0m provider\u001b[39m.\u001b[39m__use_weighting__ \u001b[39m=\u001b[39m use_weighting\n",
            "File \u001b[0;32m~/.mambaforge/envs/pii/lib/python3.10/site-packages/faker/factory.py:84\u001b[0m, in \u001b[0;36mFactory._find_provider_class\u001b[0;34m(cls, provider_path, locale)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(provider_module, \u001b[39m\"\u001b[39m\u001b[39mlocalized\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m     78\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\n\u001b[1;32m     79\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLooking for locale `\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m` in provider `\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m`.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     80\u001b[0m         locale,\n\u001b[1;32m     81\u001b[0m         provider_module\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m,\n\u001b[1;32m     82\u001b[0m     )\n\u001b[0;32m---> 84\u001b[0m     available_locales \u001b[39m=\u001b[39m list_module(provider_module)\n\u001b[1;32m     85\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m locale \u001b[39mor\u001b[39;00m locale \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m available_locales:\n\u001b[1;32m     86\u001b[0m         unavailable_locale \u001b[39m=\u001b[39m locale\n",
            "File \u001b[0;32m~/.mambaforge/envs/pii/lib/python3.10/site-packages/faker/utils/loading.py:38\u001b[0m, in \u001b[0;36mlist_module\u001b[0;34m(module)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[39mreturn\u001b[39;00m [file\u001b[39m.\u001b[39mparent\u001b[39m.\u001b[39mname \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m Path(path)\u001b[39m.\u001b[39mglob(\u001b[39m\"\u001b[39m\u001b[39m*/__init__.py\u001b[39m\u001b[39m\"\u001b[39m)]\n\u001b[1;32m     37\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 38\u001b[0m     \u001b[39mreturn\u001b[39;00m [name \u001b[39mfor\u001b[39;00m _, name, is_pkg \u001b[39min\u001b[39;00m pkgutil\u001b[39m.\u001b[39miter_modules([\u001b[39mstr\u001b[39m(path)]) \u001b[39mif\u001b[39;00m is_pkg]\n",
            "File \u001b[0;32m~/.mambaforge/envs/pii/lib/python3.10/site-packages/faker/utils/loading.py:38\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[39mreturn\u001b[39;00m [file\u001b[39m.\u001b[39mparent\u001b[39m.\u001b[39mname \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m Path(path)\u001b[39m.\u001b[39mglob(\u001b[39m\"\u001b[39m\u001b[39m*/__init__.py\u001b[39m\u001b[39m\"\u001b[39m)]\n\u001b[1;32m     37\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 38\u001b[0m     \u001b[39mreturn\u001b[39;00m [name \u001b[39mfor\u001b[39;00m _, name, is_pkg \u001b[39min\u001b[39;00m pkgutil\u001b[39m.\u001b[39miter_modules([\u001b[39mstr\u001b[39m(path)]) \u001b[39mif\u001b[39;00m is_pkg]\n",
            "File \u001b[0;32m~/.mambaforge/envs/pii/lib/python3.10/pkgutil.py:130\u001b[0m, in \u001b[0;36miter_modules\u001b[0;34m(path, prefix)\u001b[0m\n\u001b[1;32m    128\u001b[0m yielded \u001b[39m=\u001b[39m {}\n\u001b[1;32m    129\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m importers:\n\u001b[0;32m--> 130\u001b[0m     \u001b[39mfor\u001b[39;00m name, ispkg \u001b[39min\u001b[39;00m iter_importer_modules(i, prefix):\n\u001b[1;32m    131\u001b[0m         \u001b[39mif\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m yielded:\n\u001b[1;32m    132\u001b[0m             yielded[name] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
            "File \u001b[0;32m~/.mambaforge/envs/pii/lib/python3.10/pkgutil.py:173\u001b[0m, in \u001b[0;36m_iter_file_finder_modules\u001b[0;34m(importer, prefix)\u001b[0m\n\u001b[1;32m    171\u001b[0m     dircontents \u001b[39m=\u001b[39m []\n\u001b[1;32m    172\u001b[0m \u001b[39mfor\u001b[39;00m fn \u001b[39min\u001b[39;00m dircontents:\n\u001b[0;32m--> 173\u001b[0m     subname \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39;49mgetmodulename(fn)\n\u001b[1;32m    174\u001b[0m     \u001b[39mif\u001b[39;00m subname\u001b[39m==\u001b[39m\u001b[39m'\u001b[39m\u001b[39m__init__\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    175\u001b[0m         ispkg \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "if apply_pii_remediation:\n",
        "    from pii import apply_anonymization\n",
        "\n",
        "    def anon_function(ex):\n",
        "        if isinstance(ex[\"text\"], list):\n",
        "            texts = \"\\n\".join(ex[\"text\"])\n",
        "            return {\"text\": apply_anonymization(texts)[\"text\"].splitlines()}\n",
        "        else:\n",
        "            return {\"text\": apply_anonymization(ex[\"text\"])[\"text\"]}\n",
        "\n",
        "    anon_dataset = {\n",
        "        k: v.map(anon_function, load_from_cache_file=False)\n",
        "        for k, v in dataset.items()\n",
        "    }\n",
        "\n",
        "display(pd.DataFrame(anon_dataset[\"train\"][:10]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAPerLxYO13T"
      },
      "source": [
        "# Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "b0UqphFjO13T"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizerFast\n",
        "\n",
        "pm_log_section(\"Tokenizing\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4s1ZdOcAO13T"
      },
      "outputs": [],
      "source": [
        "tokenizer = (BertTokenizerFast\n",
        "                .from_pretrained(base_model)\n",
        "                .train_new_from_iterator(dataset[\"train\"][\"text\"], vocab_size))\n",
        "tokenizer.model_max_length = max_length\n",
        "\n",
        "tokenizer.save_pretrained(tokenizer_dir);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "R5UEZ5tWO13T",
        "outputId": "6e96ac93-203f-498a-cbed-fe7c32d353f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-8733602fe3778067/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-ccdc408fa5d515f3.arrow\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-8733602fe3778067/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-af8265d9613e7793.arrow\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-8733602fe3778067/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-87759a3d9dd0f88c.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-8733602fe3778067/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-efca6f5de61d8929.arrow\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-5f19dadcdb6a6e5e/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-f143f5f897564805.arrow\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-5f19dadcdb6a6e5e/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-fa6f68387b6b0473.arrow\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-5f19dadcdb6a6e5e/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-fc4ffe9c1d74bd88.arrow\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-5f19dadcdb6a6e5e/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-e77809f3d1dad5ff.arrow\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ea3fd112-7f72-4dde-be81-91b50f190779\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input_ids</th>\n",
              "      <th>token_type_ids</th>\n",
              "      <th>attention_mask</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[2, 1933, 17790, 212, 3796, 13993, 18314, 2658, 19885, 171, 214, 69, 6632, 254, 175, 7...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[2, 199, 2107, 17790, 212, 3796, 5792, 1508, 2658, 3544, 2935, 12, 49, 19394, 125, 13,...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[2, 37, 307, 17, 16755, 6995, 1973, 173, 2171, 49, 19394, 125, 214, 12751, 210, 1937, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[2, 199, 21, 18, 28, 17, 79, 110, 49, 19394, 125, 81, 16405, 16, 329, 3311, 244, 15761...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[2, 49, 19394, 125, 214, 1191, 1389, 22, 16, 307, 79, 110, 173, 3718, 6113, 144, 125, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[2, 252, 416, 5305, 173, 7524, 179, 19, 284, 11471, 16, 49, 19394, 125, 18045, 11526, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[2, 6, 14484, 162, 11497, 6, 214, 69, 855, 1727, 229, 162, 6340, 11, 87, 4210, 7321, 1...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[2, 374, 3770, 216, 162, 731, 1424, 173, 411, 3510, 832, 37, 1764, 568, 1565, 18, 3]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[2, 636, 855, 214, 3652, 184, 235, 7195, 129, 12136, 11, 87, 377, 7003, 16, 179, 766, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[2, 636, 855, 16, 1166, 226, 6, 1933, 59, 763, 6, 16, 6, 11510, 179, 7462, 6, 179, 6, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ea3fd112-7f72-4dde-be81-91b50f190779')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ea3fd112-7f72-4dde-be81-91b50f190779 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ea3fd112-7f72-4dde-be81-91b50f190779');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                                                   input_ids  \\\n",
              "0  [2, 1933, 17790, 212, 3796, 13993, 18314, 2658, 19885, 171, 214, 69, 6632, 254, 175, 7...   \n",
              "1  [2, 199, 2107, 17790, 212, 3796, 5792, 1508, 2658, 3544, 2935, 12, 49, 19394, 125, 13,...   \n",
              "2  [2, 37, 307, 17, 16755, 6995, 1973, 173, 2171, 49, 19394, 125, 214, 12751, 210, 1937, ...   \n",
              "3  [2, 199, 21, 18, 28, 17, 79, 110, 49, 19394, 125, 81, 16405, 16, 329, 3311, 244, 15761...   \n",
              "4  [2, 49, 19394, 125, 214, 1191, 1389, 22, 16, 307, 79, 110, 173, 3718, 6113, 144, 125, ...   \n",
              "5  [2, 252, 416, 5305, 173, 7524, 179, 19, 284, 11471, 16, 49, 19394, 125, 18045, 11526, ...   \n",
              "6  [2, 6, 14484, 162, 11497, 6, 214, 69, 855, 1727, 229, 162, 6340, 11, 87, 4210, 7321, 1...   \n",
              "7       [2, 374, 3770, 216, 162, 731, 1424, 173, 411, 3510, 832, 37, 1764, 568, 1565, 18, 3]   \n",
              "8  [2, 636, 855, 214, 3652, 184, 235, 7195, 129, 12136, 11, 87, 377, 7003, 16, 179, 766, ...   \n",
              "9  [2, 636, 855, 16, 1166, 226, 6, 1933, 59, 763, 6, 16, 6, 11510, 179, 7462, 6, 179, 6, ...   \n",
              "\n",
              "                                                                              token_type_ids  \\\n",
              "0                [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
              "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
              "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
              "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
              "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
              "5  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
              "6                   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
              "7                                        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
              "8             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
              "9  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
              "\n",
              "                                                                              attention_mask  \n",
              "0                [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
              "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1...  \n",
              "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1...  \n",
              "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1...  \n",
              "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1...  \n",
              "5  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1...  \n",
              "6                   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
              "7                                        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
              "8             [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
              "9  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1...  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenize_function = lambda ex: tokenizer(ex[\"text\"], truncation=True)\n",
        "\n",
        "tokenized_dataset = {\n",
        "    k: v.map(tokenize_function, remove_columns = list(v.features), **tokenize_params)\n",
        "    for k, v in dataset.items()\n",
        "}\n",
        "\n",
        "display(pd.DataFrame(tokenized_dataset[\"train\"][:10]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQ0_j1i8O13U"
      },
      "source": [
        "# Train masked language model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOzKtqKPFYLK",
        "outputId": "ca77b3ed-5fb2-49fb-8942-1ef71dbda812"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "using `logging_steps` to initialize `eval_steps` to 10000\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from transformers import (BertConfig,\n",
        "                          BertForMaskedLM,\n",
        "                          DataCollatorForLanguageModeling,\n",
        "                          Trainer,\n",
        "                          TrainingArguments)\n",
        "\n",
        "pm_log_section(\"Training MLM\")\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer = tokenizer,\n",
        "                                                mlm_probability = mlm_probability)\n",
        "\n",
        "model = BertForMaskedLM(config=BertConfig(vocab_size=tokenizer.vocab_size, **bert_config))\n",
        "\n",
        "train_args = TrainingArguments(output_dir = model_dir,\n",
        "                                  overwrite_output_dir = True,\n",
        "                                  **training_args)\n",
        "\n",
        "# def compute_metrics(eval_preds):\n",
        "#     idxs0, idxs1 = np.where(eval_preds.label_ids!=-100)\n",
        "\n",
        "#     preds = np.argmax(eval_preds.predictions[idxs0, idxs1, :], axis=-1)\n",
        "#     labels = eval_preds.label_ids[idxs0, idxs1]\n",
        "\n",
        "#     acc = (preds==labels).sum()/len(preds)\n",
        "\n",
        "#     return {\"accuracy\": acc}\n",
        "\n",
        "trainer = Trainer(model = model,\n",
        "                  args = train_args,\n",
        "                  data_collator = data_collator,\n",
        "                  # compute_metrics=compute_metrics,\n",
        "                  train_dataset = tokenized_dataset[\"train\"],\n",
        "                  eval_dataset = tokenized_dataset[\"val\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NAa2pmyXO13U",
        "outputId": "65f520f7-598b-4ca0-86be-c66d8a418a76"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 9403586\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 64\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 146932\n",
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='139778' max='146932' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [139778/146932 22:29:14 < 1:09:03, 1.73 it/s, Epoch 0.95/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>5.972700</td>\n",
              "      <td>4.935154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20000</td>\n",
              "      <td>4.702900</td>\n",
              "      <td>4.351250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30000</td>\n",
              "      <td>4.270400</td>\n",
              "      <td>4.028666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40000</td>\n",
              "      <td>4.009400</td>\n",
              "      <td>3.825895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50000</td>\n",
              "      <td>3.818900</td>\n",
              "      <td>3.638723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60000</td>\n",
              "      <td>3.662600</td>\n",
              "      <td>3.555936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70000</td>\n",
              "      <td>3.542200</td>\n",
              "      <td>3.428748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80000</td>\n",
              "      <td>3.441600</td>\n",
              "      <td>3.319535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90000</td>\n",
              "      <td>3.354700</td>\n",
              "      <td>3.251397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100000</td>\n",
              "      <td>3.283900</td>\n",
              "      <td>3.193127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110000</td>\n",
              "      <td>3.229700</td>\n",
              "      <td>3.156737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120000</td>\n",
              "      <td>3.179400</td>\n",
              "      <td>3.056212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130000</td>\n",
              "      <td>3.140000</td>\n",
              "      <td>3.053825</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ../_data/pretrain/model/checkpoint-10000\n",
            "Configuration saved in ../_data/pretrain/model/checkpoint-10000/config.json\n",
            "Model weights saved in ../_data/pretrain/model/checkpoint-10000/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ../_data/pretrain/model/checkpoint-20000\n",
            "Configuration saved in ../_data/pretrain/model/checkpoint-20000/config.json\n",
            "Model weights saved in ../_data/pretrain/model/checkpoint-20000/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ../_data/pretrain/model/checkpoint-30000\n",
            "Configuration saved in ../_data/pretrain/model/checkpoint-30000/config.json\n",
            "Model weights saved in ../_data/pretrain/model/checkpoint-30000/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ../_data/pretrain/model/checkpoint-40000\n",
            "Configuration saved in ../_data/pretrain/model/checkpoint-40000/config.json\n",
            "Model weights saved in ../_data/pretrain/model/checkpoint-40000/pytorch_model.bin\n",
            "Deleting older checkpoint [../_data/pretrain/model/checkpoint-10000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ../_data/pretrain/model/checkpoint-50000\n",
            "Configuration saved in ../_data/pretrain/model/checkpoint-50000/config.json\n",
            "Model weights saved in ../_data/pretrain/model/checkpoint-50000/pytorch_model.bin\n",
            "Deleting older checkpoint [../_data/pretrain/model/checkpoint-20000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ../_data/pretrain/model/checkpoint-60000\n",
            "Configuration saved in ../_data/pretrain/model/checkpoint-60000/config.json\n",
            "Model weights saved in ../_data/pretrain/model/checkpoint-60000/pytorch_model.bin\n",
            "Deleting older checkpoint [../_data/pretrain/model/checkpoint-30000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ../_data/pretrain/model/checkpoint-70000\n",
            "Configuration saved in ../_data/pretrain/model/checkpoint-70000/config.json\n",
            "Model weights saved in ../_data/pretrain/model/checkpoint-70000/pytorch_model.bin\n",
            "Deleting older checkpoint [../_data/pretrain/model/checkpoint-40000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ../_data/pretrain/model/checkpoint-80000\n",
            "Configuration saved in ../_data/pretrain/model/checkpoint-80000/config.json\n",
            "Model weights saved in ../_data/pretrain/model/checkpoint-80000/pytorch_model.bin\n",
            "Deleting older checkpoint [../_data/pretrain/model/checkpoint-50000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ../_data/pretrain/model/checkpoint-90000\n",
            "Configuration saved in ../_data/pretrain/model/checkpoint-90000/config.json\n",
            "Model weights saved in ../_data/pretrain/model/checkpoint-90000/pytorch_model.bin\n",
            "Deleting older checkpoint [../_data/pretrain/model/checkpoint-60000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ../_data/pretrain/model/checkpoint-100000\n",
            "Configuration saved in ../_data/pretrain/model/checkpoint-100000/config.json\n",
            "Model weights saved in ../_data/pretrain/model/checkpoint-100000/pytorch_model.bin\n",
            "Deleting older checkpoint [../_data/pretrain/model/checkpoint-70000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ../_data/pretrain/model/checkpoint-110000\n",
            "Configuration saved in ../_data/pretrain/model/checkpoint-110000/config.json\n",
            "Model weights saved in ../_data/pretrain/model/checkpoint-110000/pytorch_model.bin\n",
            "Deleting older checkpoint [../_data/pretrain/model/checkpoint-80000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ../_data/pretrain/model/checkpoint-120000\n",
            "Configuration saved in ../_data/pretrain/model/checkpoint-120000/config.json\n",
            "Model weights saved in ../_data/pretrain/model/checkpoint-120000/pytorch_model.bin\n",
            "Deleting older checkpoint [../_data/pretrain/model/checkpoint-90000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ../_data/pretrain/model/checkpoint-130000\n",
            "Configuration saved in ../_data/pretrain/model/checkpoint-130000/config.json\n",
            "Model weights saved in ../_data/pretrain/model/checkpoint-130000/pytorch_model.bin\n",
            "Deleting older checkpoint [../_data/pretrain/model/checkpoint-100000] due to args.save_total_limit\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='146932' max='146932' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [146932/146932 23:38:21, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>5.972700</td>\n",
              "      <td>4.935154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20000</td>\n",
              "      <td>4.702900</td>\n",
              "      <td>4.351250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30000</td>\n",
              "      <td>4.270400</td>\n",
              "      <td>4.028666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40000</td>\n",
              "      <td>4.009400</td>\n",
              "      <td>3.825895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50000</td>\n",
              "      <td>3.818900</td>\n",
              "      <td>3.638723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60000</td>\n",
              "      <td>3.662600</td>\n",
              "      <td>3.555936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70000</td>\n",
              "      <td>3.542200</td>\n",
              "      <td>3.428748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80000</td>\n",
              "      <td>3.441600</td>\n",
              "      <td>3.319535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90000</td>\n",
              "      <td>3.354700</td>\n",
              "      <td>3.251397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100000</td>\n",
              "      <td>3.283900</td>\n",
              "      <td>3.193127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110000</td>\n",
              "      <td>3.229700</td>\n",
              "      <td>3.156737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120000</td>\n",
              "      <td>3.179400</td>\n",
              "      <td>3.056212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130000</td>\n",
              "      <td>3.140000</td>\n",
              "      <td>3.053825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140000</td>\n",
              "      <td>3.110100</td>\n",
              "      <td>3.011493</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ../_data/pretrain/model/checkpoint-140000\n",
            "Configuration saved in ../_data/pretrain/model/checkpoint-140000/config.json\n",
            "Model weights saved in ../_data/pretrain/model/checkpoint-140000/pytorch_model.bin\n",
            "Deleting older checkpoint [../_data/pretrain/model/checkpoint-110000] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Saving model checkpoint to ../_data/pretrain/model\n",
            "Configuration saved in ../_data/pretrain/model/config.json\n",
            "Model weights saved in ../_data/pretrain/model/pytorch_model.bin\n"
          ]
        }
      ],
      "source": [
        "trainer.train()\n",
        "trainer.save_model(model_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aM8fGOc4yDXQ"
      },
      "source": [
        "# Evaluation\n",
        "Run **Setup**, then proceed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158,
          "referenced_widgets": [
            "61448b1069fc476cad83a2e7269b7dab",
            "e1bd4071bdcb48ea90be76ef4a259368",
            "75a35f697cd74f6f9a502462260376c5",
            "df7fbed3051d4d7ab95c2abd35dc62b1",
            "59360045b2b64809be2f19e350a65757",
            "9105d30b1ba54c2098b20ff51ed31c09",
            "04ec4620a5714b93aa4b91bfed64494f",
            "55396a8ca2db4196957bbc9534d3148f",
            "3df07f4b831340fc925a39e93020c27c",
            "bf4fc9d2d13d44e198d6b5d4b0d6429c",
            "bfa515cce4fe47a48f07c8862216d337"
          ]
        },
        "id": "3ikIBrosoR35",
        "outputId": "558b936f-3870-499b-97dc-7ef89518fd52"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:datasets.builder:Using custom data configuration default-5f19dadcdb6a6e5e\n",
            "WARNING:datasets.builder:Found cached dataset json (/root/.cache/huggingface/datasets/json/default-5f19dadcdb6a6e5e/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "61448b1069fc476cad83a2e7269b7dab",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-5f19dadcdb6a6e5e/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-a0bbe95aeb10886e.arrow\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-5f19dadcdb6a6e5e/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-323b973597039bdb.arrow\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-5f19dadcdb6a6e5e/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-db7da017e9dcef2f.arrow\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-5f19dadcdb6a6e5e/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-9ad7b244e6dbfe12.arrow\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import BertTokenizerFast\n",
        "\n",
        "\n",
        "pm_log_section(\"Evaluating MLM\")\n",
        "\n",
        "data_file = path.join(ds_dir, \"val_data.json\")\n",
        "if not path.isfile(data_file):  data_file += \".gz\"\n",
        "\n",
        "val_dataset = load_dataset(\"json\", data_files=data_file, field=\"data\")[\"train\"]\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained(tokenizer_dir)\n",
        "tokenize_function = lambda ex: tokenizer(ex[\"text\"], truncation=True)\n",
        "\n",
        "tokenized_val_dataset = val_dataset.map(\n",
        "    tokenize_function, \n",
        "    remove_columns=list(val_dataset.features), \n",
        "    **tokenize_params\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XpTKTrPAxqpP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from transformers import (BertForMaskedLM,\n",
        "                          DataCollatorForLanguageModeling,\n",
        "                          Trainer,\n",
        "                          TrainingArguments)\n",
        "\n",
        "\n",
        "model = BertForMaskedLM.from_pretrained(model_dir)\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer = tokenizer,\n",
        "                                                mlm_probability = mlm_probability)\n",
        "\n",
        "train_args = TrainingArguments(output_dir = model_dir,\n",
        "                               overwrite_output_dir = True,\n",
        "                               **training_args)\n",
        "\n",
        "trainer = Trainer(model = model,\n",
        "                  args = train_args,\n",
        "                  data_collator = data_collator,\n",
        "                  eval_dataset = tokenized_val_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "DhPbntblHaEI",
        "outputId": "db6a875a-11ff-4772-b767-26d5469590f3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 1174433\n",
            "  Batch size = 8\n",
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='146805' max='146805' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [146805/146805 1:14:25]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 2.975706100463867,\n",
              " 'eval_runtime': 4467.8428,\n",
              " 'eval_samples_per_second': 262.864,\n",
              " 'eval_steps_per_second': 32.858}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1Jl9IN6bneu"
      },
      "source": [
        "## Random examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XJfWs8bbRU58"
      },
      "outputs": [],
      "source": [
        "np.random.seed(0)\n",
        "\n",
        "samples = np.random.permutation(len(tokenized_val_dataset))[:5]\n",
        "samples = [tokenized_val_dataset[int(i)] for i in samples]\n",
        "\n",
        "inputs = {k: v.to(\"cuda\") for k, v in data_collator(samples).items()}\n",
        "preds = torch.argmax(model(**inputs).logits.cpu(), axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rhLTjgRrX1Lx",
        "outputId": "958d0808-3669-4d6f-8511-7194d7ffb362"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'Handball players at the 2016 Summer Olympics'\n",
            "'[MASK]ball players at the 2016 Summer [MASK]'\n",
            "'Handball players at the 2016 Summer Olympics'\n",
            "\n",
            "('Of special interest is the six petal rosette derived from the \" seven overlapping circles \" pattern, also known as \" '\n",
            " 'Sun of the Alps \" from its frequent use in alpine folk art in the 17th and 18th century.')\n",
            "('Of special interest is [MASK] six [MASK]al [MASK]tte derived from the \" seven overlapping [MASK] \" [MASK], also '\n",
            " 'known as \" Sun of the Alps \" Bark its frequent use in alpine folk art in the 17th and 18th century [MASK]')\n",
            "('Of special interest is the six spiral palette derived from the \" seven overlappings \" style, also known as \" Sun of '\n",
            " 'the Alps \", its frequent use in alpine folk art in the 17th and 18th century.')\n",
            "\n",
            "(\"For example, in Scholasticism, it was believed that God was capable of performing any miracle so long as it didn't \"\n",
            " 'lead to a logical contradiction.')\n",
            "('For example, [MASK] [MASK] [MASK]ism, it was believed that God was capable of performing any miracle so long as it '\n",
            " \"didn't [MASK] to a logical contradiction [MASK]\")\n",
            "(\"For example, in the realism, it was believed that God was capable of performing any miracle so long as it didn't \"\n",
            " 'lead to a logical contradiction.')\n",
            "\n",
            "'( 1965 - 2002 ) - bought by Airdrie United and moved to Airdrie in 2002'\n",
            "'( 1965 - 2002 ) [MASK] bought by [MASK]drie [MASK] and moved to Airdrie in 2002'\n",
            "'( 1965 - 2002 ), bought by Airdrie, and moved to Airdrie in 2002'\n",
            "\n",
            "('Indeed, in phytophagous insects ( such as aphids and lepidopterans ), holocentrism could be an evolved defense '\n",
            " 'against the production by plants of compounds able to induce chromosomal breakages ( clastogens ), whereas in other '\n",
            " 'cases, holocentrism may constitute a defense against DNA damage resulting from desiccation and / or other chromosome '\n",
            " '- breaking factors.')\n",
            "('Indeed, in phytophagous insects ( such as aphi [MASK] and lepidopterans ), [MASK]ocent [MASK] predominantly could be '\n",
            " 'an evolved defense against the production by [MASK] of compounds able to [MASK]e chromosomal [MASK]ages ( clastogens '\n",
            " '), whereas [MASK] [MASK] cases, holocentris [MASK] may constitute a defense [MASK] DNA damage resulting from '\n",
            " 'desiccation and / or Fle chromosome - breaking factors.')\n",
            "('Indeed, in phytophagous insects ( such as aphies and lepidopterans ), Innocentss could be an important defense '\n",
            " 'against the production by means of compounds able to induce chromosomal shortages ( clastogens ), whereas in other '\n",
            " 'cases, holocentrises may constitute a defense of DNA damage resulting from desiccation and / or other chromosome - '\n",
            " 'breaking factors.')\n",
            "\n"
          ]
        }
      ],
      "source": [
        "decode_kwargs = dict(\n",
        "    skip_special_tokens=False\n",
        ")\n",
        "\n",
        "for sample, input, pred in zip(samples, inputs[\"input_ids\"], preds):\n",
        "    len_sample = len(sample[\"input_ids\"])\n",
        "    pp.pprint(tokenizer.decode(sample[\"input_ids\"][1:len_sample-1], **decode_kwargs))\n",
        "    pp.pprint(tokenizer.decode(input[1:len_sample-1], **decode_kwargs))\n",
        "    pp.pprint(tokenizer.decode(pred[1:len_sample-1], **decode_kwargs))\n",
        "    print()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [
        "ZDMWt0QJO13P"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 ('pii')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "9c6a09ae61f2c394f67ff51dc946b62f1df5f97b79879dc2b09d91cc9b837b3e"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "04ec4620a5714b93aa4b91bfed64494f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "081bbf8a01104c21bf3aeffcabf5c911": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "158ba31be3c2431491108889cb9cdbf6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a55c335945642dd91cd971e1ab3882a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1fa8e54f823b468a9625a7dad673955c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3c694b6cd16c4a3ba89d852e698743f9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3df07f4b831340fc925a39e93020c27c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "422200b605f74cc984a9978adbf4c22f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_96e9641def944faabd4b23fa78a390d2",
              "IPY_MODEL_9e1375057d7e4798bb6f8b4812d264a8",
              "IPY_MODEL_658635f4acfe4d6aa71799c4ed291660"
            ],
            "layout": "IPY_MODEL_845eba9a96a54285b4fb56e74fb0ed0c"
          }
        },
        "55396a8ca2db4196957bbc9534d3148f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59360045b2b64809be2f19e350a65757": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5afcfb79d58a4f5bb5fa841d6342ed8b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61448b1069fc476cad83a2e7269b7dab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e1bd4071bdcb48ea90be76ef4a259368",
              "IPY_MODEL_75a35f697cd74f6f9a502462260376c5",
              "IPY_MODEL_df7fbed3051d4d7ab95c2abd35dc62b1"
            ],
            "layout": "IPY_MODEL_59360045b2b64809be2f19e350a65757"
          }
        },
        "658635f4acfe4d6aa71799c4ed291660": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_158ba31be3c2431491108889cb9cdbf6",
            "placeholder": "",
            "style": "IPY_MODEL_aafc33167e5d48aa886efcb0c1ae0fe0",
            "value": " 1/1 [00:00&lt;00:00, 37.24it/s]"
          }
        },
        "75a35f697cd74f6f9a502462260376c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55396a8ca2db4196957bbc9534d3148f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3df07f4b831340fc925a39e93020c27c",
            "value": 1
          }
        },
        "781884de5de9499595b98c4aeba39558": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "845eba9a96a54285b4fb56e74fb0ed0c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9105d30b1ba54c2098b20ff51ed31c09": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94f985d3ddd346d5af1f30bf323d032c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96e9641def944faabd4b23fa78a390d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5afcfb79d58a4f5bb5fa841d6342ed8b",
            "placeholder": "",
            "style": "IPY_MODEL_1a55c335945642dd91cd971e1ab3882a",
            "value": "100%"
          }
        },
        "9e1375057d7e4798bb6f8b4812d264a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_781884de5de9499595b98c4aeba39558",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e2e28cce613f446f99f1f9ce2a975c72",
            "value": 1
          }
        },
        "aafc33167e5d48aa886efcb0c1ae0fe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac0b159991074b0aa67b5c0e1a80d327": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af26006679384cf6934af5f35e5e600a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf4fc9d2d13d44e198d6b5d4b0d6429c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfa515cce4fe47a48f07c8862216d337": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0a41c2c21f545b883d726044efc0e57": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c694b6cd16c4a3ba89d852e698743f9",
            "placeholder": "",
            "style": "IPY_MODEL_ac0b159991074b0aa67b5c0e1a80d327",
            "value": "100%"
          }
        },
        "c198afd63ae14c92a68b03b8c9938d22": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af26006679384cf6934af5f35e5e600a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1fa8e54f823b468a9625a7dad673955c",
            "value": 1
          }
        },
        "c6f1c2ee06724432bc9762befd3adf2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94f985d3ddd346d5af1f30bf323d032c",
            "placeholder": "",
            "style": "IPY_MODEL_081bbf8a01104c21bf3aeffcabf5c911",
            "value": " 1/1 [00:00&lt;00:00, 19.06it/s]"
          }
        },
        "cf9c1c7d78bf4c35aebe6345fa42247a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c0a41c2c21f545b883d726044efc0e57",
              "IPY_MODEL_c198afd63ae14c92a68b03b8c9938d22",
              "IPY_MODEL_c6f1c2ee06724432bc9762befd3adf2d"
            ],
            "layout": "IPY_MODEL_d196d72c57cc48659679cf0b596a9013"
          }
        },
        "d196d72c57cc48659679cf0b596a9013": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df7fbed3051d4d7ab95c2abd35dc62b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf4fc9d2d13d44e198d6b5d4b0d6429c",
            "placeholder": "",
            "style": "IPY_MODEL_bfa515cce4fe47a48f07c8862216d337",
            "value": " 1/1 [00:00&lt;00:00, 35.84it/s]"
          }
        },
        "e1bd4071bdcb48ea90be76ef4a259368": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9105d30b1ba54c2098b20ff51ed31c09",
            "placeholder": "",
            "style": "IPY_MODEL_04ec4620a5714b93aa4b91bfed64494f",
            "value": "100%"
          }
        },
        "e2e28cce613f446f99f1f9ce2a975c72": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
