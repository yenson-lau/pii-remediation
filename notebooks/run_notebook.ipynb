{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[===== Running on testing mode =====] (0:00:00 elapsed)\n",
      "\n",
      "TESTING Parameters:\n",
      "OrderedDict([ ('dataset', '../_data/wiki/20220301.en.test'),\n",
      "              ('text_col', 'text'),\n",
      "              ('base_model', 'bert-base-cased'),\n",
      "              ('max_length', 128),\n",
      "              ('vocab_size', 20000),\n",
      "              ('tokenize_params', {'batched': True}),\n",
      "              ('tokenizer_dir', '../_data/pretrain/tokenizer'),\n",
      "              ('mlm_probability', 0.15),\n",
      "              ('bert_config', {}),\n",
      "              ( 'training_args',\n",
      "                { 'evaluation_strategy': 'steps',\n",
      "                  'logging_steps': 1,\n",
      "                  'max_steps': 3,\n",
      "                  'optim': 'adamw_torch',\n",
      "                  'per_device_train_batch_size': 128}),\n",
      "              ('model_dir', '../_data/pretrain/model')])\n",
      "\n",
      "[===== Loading dataset =====] (0:00:00 elapsed)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-e5574e295c9a56a3\n",
      "\n",
      "Using custom data configuration default-e5574e295c9a56a3\n",
      "Reusing dataset json (/Users/yenson/.cache/huggingface/datasets/json/default-e5574e295c9a56a3/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253)\n",
      "\n",
      "Reusing dataset json (/Users/yenson/.cache/huggingface/datasets/json/default-e5574e295c9a56a3/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253)\n",
      "Using custom data configuration default-e7bfbf373754ac09\n",
      "\n",
      "Using custom data configuration default-e7bfbf373754ac09\n",
      "Reusing dataset json (/Users/yenson/.cache/huggingface/datasets/json/default-e7bfbf373754ac09/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253)\n",
      "\n",
      "Reusing dataset json (/Users/yenson/.cache/huggingface/datasets/json/default-e7bfbf373754ac09/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253)\n",
      "Using custom data configuration default-f2bf3306c41d48cb\n",
      "\n",
      "Using custom data configuration default-f2bf3306c41d48cb\n",
      "Reusing dataset json (/Users/yenson/.cache/huggingface/datasets/json/default-f2bf3306c41d48cb/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253)\n",
      "\n",
      "Reusing dataset json (/Users/yenson/.cache/huggingface/datasets/json/default-f2bf3306c41d48cb/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[===== Tokenizing =====] (0:00:01 elapsed)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[===== Training MLM =====] (0:00:03 elapsed)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "***** Running training *****\n",
      "\n",
      "***** Running training *****\n",
      "  Num examples = 8788\n",
      "\n",
      "  Num examples = 8788\n",
      "  Num Epochs = 1\n",
      "\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 128\n",
      "\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n",
      "\n",
      "  Total optimization steps = 3\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "***** Running Evaluation *****\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 998\n",
      "\n",
      "  Num examples = 998\n",
      "  Batch size = 8\n",
      "\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 9.9878, 'learning_rate': 3.3333333333333335e-05, 'epoch': 0.01}\n",
      "{'eval_loss': 9.622785568237305, 'eval_accuracy': 0.045454545454545456, 'eval_runtime': 159.107, 'eval_samples_per_second': 6.273, 'eval_steps_per_second': 0.786, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 998\n",
      "\n",
      "  Num examples = 998\n",
      "  Batch size = 8\n",
      "\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 9.5692, 'learning_rate': 1.6666666666666667e-05, 'epoch': 0.03}\n",
      "{'eval_loss': 9.46419620513916, 'eval_accuracy': 0.05, 'eval_runtime': 167.4518, 'eval_samples_per_second': 5.96, 'eval_steps_per_second': 0.746, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 998\n",
      "\n",
      "  Num examples = 998\n",
      "  Batch size = 8\n",
      "\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 9.4457, 'learning_rate': 0.0, 'epoch': 0.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Saving model checkpoint to ../_data/pretrain/model\n",
      "\n",
      "Saving model checkpoint to ../_data/pretrain/model\n",
      "Configuration saved in ../_data/pretrain/model/config.json\n",
      "\n",
      "Configuration saved in ../_data/pretrain/model/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 9.32431697845459, 'eval_accuracy': 0.05210237659963437, 'eval_runtime': 171.6168, 'eval_samples_per_second': 5.815, 'eval_steps_per_second': 0.728, 'epoch': 0.04}\n",
      "{'train_runtime': 529.1835, 'train_samples_per_second': 0.726, 'train_steps_per_second': 0.006, 'train_loss': 9.667586962381998, 'epoch': 0.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ../_data/pretrain/model/pytorch_model.bin\n",
      "\n",
      "Model weights saved in ../_data/pretrain/model/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[===== Finished pretraining! =====] (0:08:56 elapsed)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import papermill as pm\n",
    "import scrapbook as sb\n",
    "import sys\n",
    "import time\n",
    "from os import path\n",
    "\n",
    "def execute_notebook(input_nb, output_nb, **params):\n",
    "    pm.execute_notebook(\n",
    "        input_nb,\n",
    "        output_nb,\n",
    "        params,\n",
    "        log_output=True,\n",
    "        stdout_file=sys.stdout,\n",
    "        stderr_file=sys.stderr,\n",
    "        progress_bar=False\n",
    "    );\n",
    "\n",
    "    return sb.read_notebook(output_nb)\n",
    "\n",
    "nb = execute_notebook(\"../eval_pii_remediation/pretrain.ipynb\",\n",
    "                      \"pretrain_test_run.ipynb\", \n",
    "                      _pm_log_sections=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('pii')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9c6a09ae61f2c394f67ff51dc946b62f1df5f97b79879dc2b09d91cc9b837b3e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
